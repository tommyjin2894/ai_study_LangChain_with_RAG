{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prompt template\n",
    "- prompt template : í”„ë¡¬í”„íŠ¸(ëª¨ë¸ì…ë ¥ê°’) ì˜ í•¨ìˆ˜í™”\n",
    "- ì–´ë– í•œ ì„œë¹„ìŠ¤ ì œì‘ì‹œ ì‚¬ìš©ìì˜ ë¶€ë‹´ì„ ëœì–´ì¤€ë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "with open(\"api_keys.json\") as f:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = json.load(f)[\"openai\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "gpt4o = ChatOpenAI(model_name=\"gpt-4o-mini\",\n",
    "                   streaming=True,\n",
    "                   callbacks=[StreamingStdOutCallbackHandler()],\n",
    "                   temperature=1,\n",
    "                   max_tokens=100)\n",
    "\n",
    "answer = gpt4o.invoke(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•ˆë…•, ê·€ì—¬ìš´ ì•„ê°€ì•¼! ğŸ˜Š ì–´ë–»ê²Œ ì§€ë‚´ê³  ìˆë‹ˆ? ì˜¤ëŠ˜ë„ ì¬ë¯¸ìˆëŠ” ê²ƒë“¤ ë§ì´ í–ˆë‹ˆ? í–‰ë³µí•œ í•˜ë£¨ ë³´ë‚´ì! ğŸ’–ğŸŒˆ"
     ]
    }
   ],
   "source": [
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"You are a kindergarten teacher. Please answer as if you were speaking to a little baby.\"),\n",
    "    HumanMessage(\"ì•ˆë…•! í•˜ìª ì—¬ ëœŒëœŒë•¨\"),\n",
    "]\n",
    "\n",
    "responses = gpt4o.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” êµìˆ˜ë‹˜ì…ë‹ˆë‹¤. ì£¼ë¡œ í•™ìƒë“¤ì—ê²Œ ì§€ì‹ì„ ì „ë‹¬í•˜ê³ , ì—°êµ¬ë¥¼ ìˆ˜í–‰í•˜ë©°, í•™ë¬¸ì  ë°œì „ì— ê¸°ì—¬í•˜ëŠ” ì¼ì„ í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì—¬ëŸ¬ë¶„ì˜ í•™ìŠµì„ ë•ê³ , ê¶ê¸ˆí•œ ì ì— ëŒ€í•´ í•¨ê»˜ ê³ ë¯¼í•˜ëŠ” ê²ƒì€ ì œ ì—­í•  ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤. í˜¹ì‹œ ì–´ë–¤ ê³¼ëª©ì— ëŒ€í•´ ì§ˆë¬¸ì´ ìˆìœ¼ì‹ ê°€ìš”?"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "\n",
    "system_prompt = PromptTemplate.from_template(\"You are a {profession}. Please answer as if you were speaking to a {target}\")\n",
    "\n",
    "# format_prompt ë¡œ ì„¤ì •ì„ í•´ì¤€ë‹¤. ë°©ë²• 1\n",
    "system_prompt_value = system_prompt.format_prompt(profession = \"expert job planner\", target = \"job seeker in ai industry\")\n",
    "\n",
    "messages = [\n",
    "    # SystemMessage(system_prompt_value.to_string()), # ë°©ë²• 1\n",
    "    SystemMessage(system_prompt.format(profession = \"êµìˆ˜ë‹˜\", target = \"ëŒ€í•™ìƒ\")), # ë°©ë²• 2\n",
    "    HumanMessage(\"ë‹¹ì‹ ì˜ ì§ì—…ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?\"),\n",
    "]\n",
    "gpt4o.invoke(messages);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chatting Promplt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì™„ì „í•œ ë¡œë´‡ ì œì‘ ê³„íšì€ ë‹¤ìŒê³¼ ê°™ì€ ë‹¨ê³„ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤:\n",
      "\n",
      "1. **ëª©í‘œ ì„¤ì •**: ë¡œë´‡ì˜ ìš©ë„ì™€ ê¸°ëŠ¥ ì •ì˜ (ì˜ˆ: ê°€ì •ìš©, ì‚°ì—…ìš©, êµìœ¡ìš© ë“±).\n",
      "\n",
      "2. **ì„¤ê³„**: \n",
      "   - ê¸°ê³„ì  êµ¬ì¡° ì„¤ê³„ (CAD ì†Œí”„íŠ¸ì›¨ì–´ ì‚¬ìš©).\n",
      "   - ì „ì íšŒë¡œ ì„¤ê³„ (ì„¼ì„œ, ëª¨í„°, ë§ˆì´í¬ë¡œì»¨íŠ¸ë¡¤ëŸ¬ ë“±).\n",
      "\n",
      "3. **ë¶€í’ˆ ì„ ì •**: \n",
      "   - í•„ìš”í•œ ë¶€í’ˆ ëª©ë¡ ì‘ì„±.\n",
      "   - ë¶€í’ˆ ê³µê¸‰ì²˜ ì¡°ì‚¬ ë° êµ¬ë§¤.\n",
      "\n",
      "4. **ì¡°ë¦½**: \n",
      "   - ê¸°ê³„ì  ì¡°ë¦½ ë° ì „ì íšŒë¡œ ì—°ê²°.\n",
      "   - ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ ë° ë¡œë´‡ ì œì–´ ì‹œìŠ¤í…œ êµ¬ì¶•.\n",
      "\n",
      "5. **í…ŒìŠ¤íŠ¸ ë° ê°œì„ **: \n",
      "   - ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ë° ì„±ëŠ¥ í‰ê°€.\n",
      "   - ë¬¸ì œì  ìˆ˜ì • ë° ìµœì í™”.\n",
      "\n",
      "ê° ë‹¨ê³„ì—ì„œì˜ ì„¸ë¶€ ê³„íšê³¼ ì¼ì • ì„¤ì •ì´ ì¤‘ìš”í•©ë‹ˆë‹¤."
     ]
    }
   ],
   "source": [
    "from langchain.prompts import (ChatPromptTemplate,\n",
    "                               PromptTemplate,\n",
    "                               SystemMessagePromptTemplate,\n",
    "                               AIMessagePromptTemplate,\n",
    "                               HumanMessagePromptTemplate)\n",
    "\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "gpt4o = ChatOpenAI(model_name=\"gpt-4o-mini\",\n",
    "                   streaming=True,\n",
    "                   callbacks=[StreamingStdOutCallbackHandler()],\n",
    "                   temperature=0.5,\n",
    "                   max_tokens=1000)\n",
    "\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(\"ì—­í•  ì€{system_prompt} ì…ë‹ˆë‹¤. ëŒ€ë‹µí•­ëª© {N__} ì´í•˜\")\n",
    "human__message_prompt = HumanMessagePromptTemplate.from_template(\"ì§ˆë¬¸ : {human_prompt}\")\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt,human__message_prompt])\n",
    "\n",
    "answer = gpt4o.invoke(chat_prompt.format_prompt(system_prompt= \"ì² ì €í•œ ê³„íš ê¸°íšì\",\n",
    "                                                N__ = \"5\",\n",
    "                                                human_prompt = \"ì™„ì „í•œ ë¡œë´‡ ì œì‘ ê³„íš\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### template for few-shot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ì—¬ëŸ¬ ê²°ê³¼ë¬¼ì„ ì˜ˆì‹œë¡œ ë‚´ëŠ” few-shot í”„ë¡¬í”„íŒ…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"question\" : \"ë¡œë´‡ ì´ë¯¸ì§€ ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ë§Œë“¤ì–´ì¤˜\",\n",
    "        \"answer\" : \"ë¡œë´‡, ê³µìƒê³¼í•™, ìš°ì£¼, ì§€êµ¬\"\n",
    "    },\n",
    "    {\n",
    "        \"question\" : \"ë™í™” ì´ë¯¸ì§€ ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ë§Œë“¤ì–´ì¤˜?\",\n",
    "        \"answer\" : \"ì‚°, í† ë¼, ê±°ë¶ì´, ë‹¬ë¦¬ê¸°\"\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_prompt = PromptTemplate(input_variables=[\"question\",\"answer\"], template=\"question : {question} \\nanswer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'question : ë¡œë´‡ ì´ë¯¸ì§€ ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ë§Œë“¤ì–´ì¤˜ \\nanswer: ë¡œë´‡, ê³µìƒê³¼í•™, ìš°ì£¼, ì§€êµ¬'"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples_prompt.format(**examples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: ë©‹ì§„ ë’·ê³¨ëª©, í™”ë ¤í•œ ê·¸ë˜í”¼í‹°, ë‚ ì•„ë‹¤ë‹ˆëŠ” ìƒˆ, í–‡ì‚´, ë„ì‹œ í’ê²½"
     ]
    }
   ],
   "source": [
    "few_prompt = FewShotPromptTemplate(\n",
    "    examples = examples, # ì°¸ê³  ì˜ˆì‹œ ëŒ€ìƒ\n",
    "    example_prompt = examples_prompt, # í‘œí˜„ ì •ì˜ í…œí”Œë¦¿\n",
    "    suffix = \"question : {input}ì´ë¯¸ì§€ ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ë§Œë“¤ì–´ì¤˜\", # ì‹¤ì œ ì‚¬ìš© í…œí”Œë¦¿\n",
    "    input_variables = [\"input\"]\n",
    ")\n",
    "answer = gpt4o.invoke(few_prompt.format(input = \"ë©‹ì§„ ë’·ê³¨ëª©ì—ì„œ ë‚ ì•„ë‹¤ë‹ˆëŠ” ìƒˆ\")) # ì›í•˜ëŠ” í˜•ì‹ì˜ í…œí”Œë¦¿ì´ ìƒì„±ë¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¬¼ë¡ ì…ë‹ˆë‹¤! ë©‹ì§„ ë’·ê³¨ëª©ì—ì„œ ë‚ ì•„ë‹¤ë‹ˆëŠ” ìƒˆ ì´ë¯¸ì§€ë¥¼ ìœ„í•œ í”„ë¡¬í”„íŠ¸ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "\"í™”ì°½í•œ ì˜¤í›„, ê³ í’ìŠ¤ëŸ¬ìš´ ë²½ëŒ ê±´ë¬¼ê³¼ í™”ë ¤í•œ ê·¸ë˜í”¼í‹°ë¡œ ê°€ë“í•œ ë’·ê³¨ëª©. ê·¸ ì‚¬ì´ë¡œ ë‹¤ì–‘í•œ ìƒ‰ê¹”ì˜ ìƒˆë“¤ì´ ììœ ë¡­ê²Œ ë‚ ì•„ë‹¤ë‹ˆë©°, í–‡ì‚´ì— ë°˜ì§ì´ëŠ” ê¹ƒí„¸ì´ ì•„ë¦„ë‹µê²Œ ë¹›ë‚œë‹¤. ë’·ê³¨ëª©ì˜ ì‘ì€ ì¹´í˜ í…Œë¼ìŠ¤ì—ëŠ” ì‚¬ëŒë“¤ì´ ì•‰ì•„ ìƒˆë“¤ì„ ë°”ë¼ë³´ë©° ì—¬ìœ ë¡œìš´ ì‹œê°„ì„ ë³´ë‚´ê³  ìˆë‹¤. ìƒˆë“¤ì˜ ë‚ ê°¯ì§“ì´ ìƒë™ê° ë„˜ì¹˜ëŠ” ì¥ë©´ì„ ë§Œë“¤ì–´ë‚´ëŠ” ìˆœê°„ì„ í¬ì°©í•œ ì´ë¯¸ì§€.\"\n",
      "\n",
      "ì´ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ì›í•˜ëŠ” ì´ë¯¸ì§€ë¥¼ ìƒì„±í•´ë³´ì„¸ìš”!"
     ]
    }
   ],
   "source": [
    "gpt4o.invoke(\"ë©‹ì§„ ë’·ê³¨ëª©ì—ì„œ ë‚ ì•„ë‹¤ë‹ˆëŠ” ìƒˆì´ë¯¸ì§€ë¥¼ ìœ„í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•´ì¤˜\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='answer: ë©‹ì§„ ë’·ê³¨ëª©, í™”ë ¤í•œ ê·¸ë˜í”¼í‹°, ë‚ ì•„ë‹¤ë‹ˆëŠ” ìƒˆ, í–‡ì‚´, ë„ì‹œ í’ê²½' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0705bf87c0'} id='run-10767110-e047-4a43-9e2d-25a16ab45e71-0'\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Selector(ë™ì  Few-shot)\n",
    "- `SemanticSimilarityExampleSelector` : ì˜ë¯¸ì˜ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•˜ì—¬ ì ì ˆí•œ ì˜ˆì‹œë¥¼ ì„ íƒ\n",
    "- `OpenAIEmbeddings()` : í…ìŠ¤íŠ¸ì˜ ë²¡í„°í™” (ì„ë² ë”©í™”)\n",
    "- `Chroma` : ë²¡í„°í™”í•˜ì—¬ ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.example_selector import SemanticSimilarityExampleSelector # ì‚¬ìš©ì ì…ë ¥ê³¼, ì˜ˆì‹œ ìƒ˜í”Œì˜ ìœ ì‚¬ë„ ë¹„êµ\n",
    "from langchain.vectorstores import Chroma # ì„ë² ë”© ëœ ë²¡í„°ë¥¼ ë¹„êµ\n",
    "from langchain.embeddings import OpenAIEmbeddings # ë¬¸ìì˜ ì„ë² ë”© (ìˆ˜ì¹˜í™”)\n",
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\",\"output\"],\n",
    "    template=\"input = {input}, output = {output}\",\n",
    ")\n",
    "\n",
    "examples = [\n",
    "    {\"input\" : \"happy\", \"output\" : \"unhappy\"},\n",
    "    {\"input\" : \"plane\", \"output\" : \"ship\"},\n",
    "    {\"input\" : \"big plane\", \"output\" : \"small plane\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_selector = SemanticSimilarityExampleSelector.from_examples( # ì˜ë¯¸ì  ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•˜ì—¬\n",
    "    examples=examples, # ì˜ˆì‹œs\n",
    "    embeddings=OpenAIEmbeddings(), # ì„ë² ë”© ë²¡í„°ë¼ì´ì œì´ì…˜\n",
    "    vectorstore_cls=Chroma, # ë²¡í„° ì €ì¥ ì†Œ\n",
    "    k=1 # ê°€ì¥ ìœ ì‚¬í•œ ìƒìœ„ k ê°œ\n",
    ")\n",
    "\n",
    "similar_prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"give me an opposite word\",\n",
    "    suffix=\"input is {word}, and output is\",\n",
    "    input_variables = [\"word\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give me an opposite word\n",
      "\n",
      "input = plane, output = ship\n",
      "\n",
      "input is manpower, and output is\n"
     ]
    }
   ],
   "source": [
    "print(similar_prompt.format(word=\"manpower\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output = automation"
     ]
    }
   ],
   "source": [
    "gpt4o.invoke(similar_prompt.format(word=\"manpower\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### out parserë¥¼ ì´ìš©í•˜ì—¬ ì¶œë ¥ê°’ ì¡°ì • (ì„œë¹„ìŠ¤ ê²°í•©)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_instuctions = output_parser.get_format_instructions()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"give me 5 {subject} recommends. \\{format_instuctions}\",\n",
    "    input_variables=[\"subject\"], # ì‚¬ìš©ì ì…ë ¥ë¶€ë¶„\n",
    "    partial_variables={\"format_instructions\": format_instuctions}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'give me 5 nice place to get a job recommends. \\\\Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_prompt = prompt.format(subject=\"nice place to get a job\",\n",
    "                             format_instuctions = format_instuctions)\n",
    "input_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google, Microsoft, IBM, Amazon, Salesforce"
     ]
    }
   ],
   "source": [
    "gpt4o.invoke(input_prompt);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
