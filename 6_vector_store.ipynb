{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pure Vector DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- DB 엔에 vector 형태의 값만 저장\n",
    "    - Pinecone\n",
    "    - Qdrant\n",
    "    - **Chroma** 무료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chroma 이용\n",
    "\n",
    "# !pip install chromadb tiktoken transformers sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "def length_from_tokens(text):\n",
    "    tokens = tokenizer.encode(text)\n",
    "    return len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 11:11:54.174201: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733191914.192094   15777 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733191914.196630   15777 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-03 11:11:54.213028: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores.chroma import Chroma\n",
    "from langchain.document_loaders import TextLoader, PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"docs/doc_1.pdf\")\n",
    "pages_ = loader.load_and_split()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=10,\n",
    "                                               chunk_overlap=5,\n",
    "                                               length_function=length_from_tokens)\n",
    "docs = text_splitter.split_documents(pages_)\n",
    "\n",
    "from langchain.embeddings.huggingface import HuggingFaceBgeEmbeddings\n",
    "\n",
    "# model_name = \"jhgan/ko-sbert-nli\" # 한국어 모델\n",
    "model_name = \"BAAI/bge-small-en\"\n",
    "model_kwargs = {\"device\":\"cpu\"}\n",
    "encode_kwargs = {\"mormalize_embeddings\":True}\n",
    "\n",
    "hf_embedding_model = HuggingFaceBgeEmbeddings(\n",
    "    model_name = model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Chroma.from_documents(docs, hf_embedding_model) # 설명 : docs의 embeded vectors 를 chromadb 에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'page': 1, 'source': 'docs/doc_1.pdf'}, page_content='Tokyo is on fire'),\n",
       " Document(metadata={'page': 0, 'source': 'docs/doc_1.pdf'}, page_content='Tokyo is on fire'),\n",
       " Document(metadata={'page': 0, 'source': 'docs/doc_1.pdf'}, page_content='Tokyo is on fire')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"which place is burning\"\n",
    "docs = db.similarity_search(query, k=3) # 유사도 검색\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 3, updating n_results = 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'page': 1, 'source': 'docs/doc_1.pdf'}, page_content='Tokyo is on fire'),\n",
       " Document(metadata={'page': 0, 'source': 'docs/doc_1.pdf'}, page_content='Tokyo is on fire'),\n",
       " Document(metadata={'page': 0, 'source': 'docs/doc_1.pdf'}, page_content='Tokyo is on fire')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 로컬 db 에 저장하기\n",
    "\n",
    "db_saved = Chroma.from_documents(docs, hf_embedding_model, persist_directory=\"vectordb/docs_db\")\n",
    "docs = db_saved.similarity_search(query)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15777/1111290880.py:3: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  db_from_saved = Chroma(persist_directory=\"vectordb/docs_db/\",\n",
      "Number of requested results 4 is greater than number of elements in index 3, updating n_results = 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'page': 1, 'source': 'docs/doc_1.pdf'}, page_content='Tokyo is on fire'),\n",
       " Document(metadata={'page': 0, 'source': 'docs/doc_1.pdf'}, page_content='Tokyo is on fire'),\n",
       " Document(metadata={'page': 0, 'source': 'docs/doc_1.pdf'}, page_content='Tokyo is on fire')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 로컬 db 에서 불로오기\n",
    " \n",
    "db_from_saved = Chroma(persist_directory=\"vectordb/docs_db/\",\n",
    "                       embedding_function=hf_embedding_model)\n",
    "docs = db_from_saved.similarity_search(query)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "점수 : 0.7820780275093144\n"
     ]
    }
   ],
   "source": [
    "# 유사도 점수와 함께 반환\n",
    "\n",
    "docs = db_from_saved.similarity_search_with_relevance_scores(query, k=1)\n",
    "print('점수 :',docs[-1][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vectors similarity 계산에 특화되어 있는 라이브러리\n",
    "    - FAISS from(Meta) : 저장 및 유사도 계산 (유지보수에 어렵다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as before---\n",
    "loader = PyPDFLoader(\"docs/doc_1.pdf\")\n",
    "pages_ = loader.load_and_split()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=10,\n",
    "                                               chunk_overlap=5,\n",
    "                                               length_function=length_from_tokens)\n",
    "docs = text_splitter.split_documents(pages_)\n",
    "\n",
    "from langchain.embeddings.huggingface import HuggingFaceBgeEmbeddings\n",
    "\n",
    "# model_name = \"jhgan/ko-sbert-nli\" # 한국어 모델\n",
    "model_name = \"BAAI/bge-small-en\"\n",
    "model_kwargs = {\"device\":\"cpu\"}\n",
    "encode_kwargs = {\"mormalize_embeddings\":True}\n",
    "\n",
    "hf_embedding_model = HuggingFaceBgeEmbeddings(\n",
    "    model_name = model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs,\n",
    ")\n",
    "# --------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = FAISS.from_documents(docs, hf_embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'docs/doc_1.pdf', 'page': 0}, page_content='Tokyo is on fire'),\n",
       " Document(metadata={'source': 'docs/doc_1.pdf', 'page': 0}, page_content='Tokyo is on fire'),\n",
       " Document(metadata={'source': 'docs/doc_1.pdf', 'page': 0}, page_content='Tokyo is on fire'),\n",
       " Document(metadata={'source': 'docs/doc_1.pdf', 'page': 0}, page_content='Tokyo is on fire')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.similarity_search(\"which was burned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.save_local(\"vectordb/FAISS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'source': 'docs/doc_1.pdf', 'page': 0}, page_content='Tokyo is on fire'),\n",
       "  0.7565947427384916),\n",
       " (Document(metadata={'source': 'docs/doc_1.pdf', 'page': 0}, page_content='Tokyo is on fire'),\n",
       "  0.7565947427384916),\n",
       " (Document(metadata={'source': 'docs/doc_1.pdf', 'page': 0}, page_content='Tokyo is on fire'),\n",
       "  0.7565947427384916),\n",
       " (Document(metadata={'source': 'docs/doc_1.pdf', 'page': 0}, page_content='Tokyo is on fire'),\n",
       "  0.7565947427384916)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faiss_db_from_saved = FAISS.load_local(\"vectordb/FAISS\", hf_embedding_model, allow_dangerous_deserialization=True)\n",
    "faiss_result = faiss_db_from_saved._similarity_search_with_relevance_scores(\"which was burned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "찾은 문장   : Tokyo is on fire\n",
      "메타 데이터 : {'source': 'docs/doc_1.pdf', 'page': 0}\n",
      "유사도      : 0.7565947427384916\n",
      "\n",
      "찾은 문장   : Tokyo is on fire\n",
      "메타 데이터 : {'source': 'docs/doc_1.pdf', 'page': 0}\n",
      "유사도      : 0.7565947427384916\n",
      "\n",
      "찾은 문장   : Tokyo is on fire\n",
      "메타 데이터 : {'source': 'docs/doc_1.pdf', 'page': 0}\n",
      "유사도      : 0.7565947427384916\n",
      "\n",
      "찾은 문장   : Tokyo is on fire\n",
      "메타 데이터 : {'source': 'docs/doc_1.pdf', 'page': 0}\n",
      "유사도      : 0.7565947427384916\n"
     ]
    }
   ],
   "source": [
    "for doc, score in faiss_result:\n",
    "    print(f\"\"\"\n",
    "찾은 문장   : {doc.page_content}\n",
    "메타 데이터 : {doc.metadata}\n",
    "유사도      : {score}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'docs/doc_1.pdf', 'page': 0}, page_content='Tokyo is on fire'),\n",
       " Document(metadata={'source': 'docs/doc_1.pdf', 'page': 0}, page_content=\"I'll take you where surely you have never\"),\n",
       " Document(metadata={'source': 'docs/doc_1.pdf', 'page': 0}, page_content=\"All right in the fight I'm okay,\"),\n",
       " Document(metadata={'source': 'docs/doc_1.pdf', 'page': 0}, page_content='No one quit the radio'),\n",
       " Document(metadata={'source': 'docs/doc_1.pdf', 'page': 0}, page_content='No other places like that in the world,')]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faiss_result = faiss_db_from_saved.max_marginal_relevance_search(\"which place wa burned\", fetch_k=100, k=5, lambda_mult=0.3)\n",
    "faiss_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- max_marginal_relevance_search 다양성을 추구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "찾은 문장   : Tokyo is on fire\n",
      "메타 데이터 : {'source': 'docs/doc_1.pdf', 'page': 0}\n",
      "\n",
      "찾은 문장   : I'll take you where surely you have never\n",
      "메타 데이터 : {'source': 'docs/doc_1.pdf', 'page': 0}\n",
      "\n",
      "찾은 문장   : All right in the fight I'm okay,\n",
      "메타 데이터 : {'source': 'docs/doc_1.pdf', 'page': 0}\n",
      "\n",
      "찾은 문장   : No one quit the radio\n",
      "메타 데이터 : {'source': 'docs/doc_1.pdf', 'page': 0}\n",
      "\n",
      "찾은 문장   : No other places like that in the world,\n",
      "메타 데이터 : {'source': 'docs/doc_1.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "for doc in faiss_result:\n",
    "    print(f\"\"\"\n",
    "찾은 문장   : {doc.page_content}\n",
    "메타 데이터 : {doc.metadata}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity Search with Score 와 Similarity Search with Relevance Score\n",
    "1. Similarity Search with Score\n",
    "\n",
    "    낮을수록 좋다, 특정 유사성을 기준으로 한 검색에서.\n",
    "    예를 들어, **유클리드 거리(Euclidean Distance)** 나 **맨해튼 거리(Manhattan Distance)** 등을 이용하고, 거리가 작을수록 두 항목이 유사.\n",
    "\n",
    "2. Similarity Search with Relevance Score\n",
    "\n",
    "    높을수록 좋습니다, 관련성을 기준으로 한 검색에서.\n",
    "    검색 결과에서 사용자의 쿼리와 결과 간의 **관련성을 평가하는 점수**입니다.\n",
    "    이 점수가 높을수록, 검색 결과가 사용자의 의도나 쿼리와 더 관련성이 높다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
