{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기본적인 RAG 의 구조\n",
    "\n",
    "문서 로딩 ➡️ 청크 스플릿 ➡️ 임베딩 ➡️ 벡터스토어 ➡️ <u>**리트리버**</u>로 유사문장 파악 ➡️ 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <u>주요 필요 사항</u>\n",
    "    - **Multi-query** : RAG 시스템은 프롬프트 엔지니어링 없이도 좋은 결과를 내야함\n",
    "        - 사용자의 질문을 여러개의 유사 질문으로 재 생성\n",
    "    - **Parent-Document** : 참고 문서의 앞뒤 문맥을 잘 파악해 내야함\n",
    "        - 청크를 포함하고 있는 페이지 documents를 불러온다.\n",
    "        - 즉 유사문서의 부모(parent) 문서를 참조\n",
    "    - **Self-Querying** : 쿼리 (시멘틱 이 아닌) 가 필요하다.\n",
    "        - 문서 데이터 기반으로 필터링 생성 (쿼리 생성)\n",
    "            - 평점이 9점 이상인 df 영화 추천\n",
    "            - rating > 9, genre == \"sf\"\n",
    "            - 스티븐 스필버그의 쥬라기 공원이 있습니다.\n",
    "            - 엑셀과, csv 등의 테이블 데이터에 유리하다\n",
    "    - **Time-weighted** : 최신 자료 위주로 참고하게 끔."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q langchain pypdf sentence_transformers chromadb openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-query Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "/tmp/ipykernel_2727/3147827098.py:19: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=model_name,\n",
      "2024-12-05 16:30:42.052996: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733383842.070148    2727 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733383842.075468    2727 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-05 16:30:42.092927: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# loader\n",
    "urls = \"https://alltommysworks.com/gan/\"\n",
    "loader = WebBaseLoader(urls)\n",
    "docs = loader.load()\n",
    "\n",
    "# splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=0)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# VectorDB\n",
    "model_name = \"jhgan/ko-sbert-nli\" # 임베딩 이용\n",
    "encode_kwargs = {\"normalize_embeddings\": True}\n",
    "embeddings = HuggingFaceEmbeddings(model_name=model_name,\n",
    "                                   encode_kwargs=encode_kwargs)\n",
    "vector_db = Chroma.from_documents(splits, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain_openai import ChatOpenAI\n",
    "import json\n",
    "\n",
    "with open(\"api_keys.json\") as f:\n",
    "    OPENAI_API_KEY = json.load(f)[\"openai\"]\n",
    "\n",
    "question = \"gan 이란 무엇인가요? (한글로)\"\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)\n",
    "mq_retriever = MultiQueryRetriever.from_llm(\n",
    "    retriever=vector_db.as_retriever(), llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig()\n",
    "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2727/1720634346.py:1: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  find_docs = mq_retriever.get_relevant_documents(question)\n",
      "INFO:langchain.retrievers.multi_query:Generated queries: ['1. gan은 무엇을 의미하나요?', '2. gan이란 무슨 뜻인가요?', '3. gan은 어떤 것을 가리키는지 알려주세요.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "find_docs = mq_retriever.get_relevant_documents(question)\n",
    "print(len(find_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parent_document Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ParentDocumentRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.storage import InMemoryStore \n",
    "                            # dict 형태로 저장 parent와 child 가 엮여있어 저장됨\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = [\n",
    "    PyPDFLoader(\"docs/doc_1.pdf\"),\n",
    "    PyPDFLoader(\"docs/portfolio.pdf\"),\n",
    "    PyPDFLoader(\"docs/resume.pdf\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load_and_split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('jhgan/ko-sbert-nli',\n",
       " {'normalize_embeddings': True},\n",
       " HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "   (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "   (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       " ), model_name='jhgan/ko-sbert-nli', cache_folder=None, model_kwargs={}, encode_kwargs={'normalize_embeddings': True}, multi_process=False, show_progress=False))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name, encode_kwargs, embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2727/1083163943.py:3: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(\n"
     ]
    }
   ],
   "source": [
    "child_splitter = RecursiveCharacterTextSplitter(chunk_size = 250,\n",
    "                                                chunk_overlap = 0)\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"full_docs\",\n",
    "    embedding_function=embeddings,\n",
    ")\n",
    "store = InMemoryStore()\n",
    "retriever = ParentDocumentRetriever(\n",
    "    vectorstore= vectorstore,\n",
    "    docstore=store,\n",
    "    child_splitter=child_splitter,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.add_documents(docs, ids=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "자식 docs 의 토큰수\n",
      "179\n",
      "232\n",
      "249\n",
      "124\n"
     ]
    }
   ],
   "source": [
    "sub_docs = vectorstore.similarity_search(\"사용한 주요 성과 지표\")\n",
    "# 자식 doc\n",
    "print(\"자식 docs 의 토큰수\")\n",
    "for doc in sub_docs:\n",
    "    print(len(doc.page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "부모 docs 의 토큰수\n",
      "415\n",
      "394\n",
      "1463\n"
     ]
    }
   ],
   "source": [
    "# 부모 docs\n",
    "print(\"부모 docs 의 토큰수\")\n",
    "par_docs = retriever.get_relevant_documents(\"사용한 주요 성과 지표\")\n",
    "for r in par_docs:\n",
    "    print(len(r.page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First doc from sub_docs:\n",
      "글길이: 179 \n",
      "\n",
      "- ICT 인증 기관에 따라 평가지표 설정\n",
      "MAPs, BLEUs, METEOR, ROUGEs 등\n",
      "- 성능 분석 및 비교하여 모델 선택\n",
      "- 훈련 결과 시각화\n",
      "시스템 설계 및 구축\n",
      "- Docker 컨테이너 구축(WSL2 우분투 이용)\n",
      "- Streamlit 및 FastAPI 구축\n",
      "- Log 설계하여 성능지표, 모델 결과 추적\n",
      "----------------------------------------------------------------------------------------------------\n",
      "First doc from sub_docs:\n",
      "글길이: 415 \n",
      "\n",
      "SNS 사진 분석 댓글 및 피드백 생성 모델\n",
      "기여한 내용\n",
      "5\n",
      "전처리 과정\n",
      "- 기존 어노테이션을 CoCo 데이터 형식으로 변환\n",
      "- YOLO 형식에 맞게 레이블 및 이미지를 재구성\n",
      "- 언어 모델 지식 증류 기법을 적용하여 데이터셋 생성 \n",
      "모델 설계 및 Fitting\n",
      "- 언어 모델 선정 및 파인튜닝\n",
      "- 객체 인식 모델 선정 및 파인 튜닝\n",
      "- 각 모델별 하이퍼 파라미터 튜닝  \n",
      "- 모델 구조도 작성(draw.io)\n",
      "모델 평가\n",
      "- ICT 인증 기관에 따라 평가지표 설정\n",
      "MAPs, BLEUs, METEOR, ROUGEs 등\n",
      "- 성능 분석 및 비교하여 모델 선택\n",
      "- 훈련 결과 시각화\n",
      "시스템 설계 및 구축\n",
      "- Docker 컨테이너 구축(WSL2 우분투 이용)\n",
      "- Streamlit 및 FastAPI 구축\n",
      "- Log 설계하여 성능지표, 모델 결과 추적\n"
     ]
    }
   ],
   "source": [
    "print('First doc from sub_docs:',)\n",
    "print('글길이:',len(sub_docs[0].page_content),\"\\n\")\n",
    "print(sub_docs[0].page_content)\n",
    "print(\"-\"*100)\n",
    "print('First doc from sub_docs:',)\n",
    "print('글길이:',len(par_docs[0].page_content),\"\\n\")\n",
    "print(par_docs[0].page_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 페이지 청크가 길때 : child 스플리터 뿐 아니라, parent 스플리터도 청크를 정해주어 분해한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitter 설정\n",
    "parent_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=0)\n",
    "child_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=0)\n",
    "\n",
    "# 임베딩 함수 설정\n",
    "embedding_function = embeddings  # embeddings가 제대로 정의되었는지 확인하세요.\n",
    "\n",
    "# VectorStore 설정\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"full_docs\",\n",
    "    embedding_function=embedding_function,\n",
    ")\n",
    "\n",
    "# InMemoryStore 설정\n",
    "store = InMemoryStore()\n",
    "\n",
    "# ParentDocumentRetriever 설정\n",
    "retriever_double_splitter = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=store,\n",
    "    child_splitter=child_splitter,\n",
    "    parent_splitter=parent_splitter,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_double_splitter.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(store.yield_keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "자식 docs 의 토큰수\n",
      "50\n",
      "86\n",
      "179\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "sub_docs = vectorstore.similarity_search(\"성과 지표\")\n",
    "# 자식 doc\n",
    "print(\"자식 docs 의 토큰수\")\n",
    "for doc in sub_docs:\n",
    "    print(len(doc.page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "부모 docs 의 토큰수\n",
      "150\n",
      "197\n",
      "197\n"
     ]
    }
   ],
   "source": [
    "# 부모 docs\n",
    "print(\"부모 docs 의 토큰수\")\n",
    "par_docs = retriever_double_splitter.get_relevant_documents(\"성과 지표\")\n",
    "for r in par_docs:\n",
    "    print(len(r.page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First doc from sub_docs:\n",
      "글길이: 50 \n",
      "\n",
      "Precision, ROC-AUC, F1-Score등다양한성능지표를활용하여모델유효성평가 .\n",
      "----------------------------------------------------------------------------------------------------\n",
      "First doc from sub_docs:\n",
      "글길이: 150 \n",
      "\n",
      "다양한샘플링기법(ROS, RUS, SMOTE, ENN, SMOTEENN등 ) 을통해데이터불균형문제개선 .- StackedModel 앙상블기법을통해F1-score최대40%향상 .- Precision, ROC-AUC, F1-Score등다양한성능지표를활용하여모델유효성평가 .\n"
     ]
    }
   ],
   "source": [
    "print('First doc from sub_docs:',)\n",
    "print('글길이:',len(sub_docs[0].page_content),\"\\n\")\n",
    "print(sub_docs[0].page_content)\n",
    "print(\"-\"*100)\n",
    "print('First doc from sub_docs:',)\n",
    "print('글길이:',len(par_docs[0].page_content),\"\\n\")\n",
    "print(par_docs[0].page_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-Querying Retreiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade --quiet lark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "docs = [\n",
    "    Document(page_content=\"성격: 적극적이고 리더십이 뛰어나며 팀워크를 중요시하는 후보자. 여러 프로젝트에서 리더 역할을 맡았으며, 목표 달성을 위한 헌신적인 노력으로 성과를 이끌어낸 경험이 있습니다.\",\n",
    "             metadata={\"experience\": \"5년간 프로젝트 관리 경험\", \"skills\": \"Leadership, Teamwork, Project Management\", \"education\": \"경영학 석사\", \"year\": 1993}),\n",
    "    Document(page_content=\"성격: 분석적이고 꼼꼼한 성격을 가진 후보자. 데이터 분석과 문제 해결 능력이 뛰어나며, 팀과 협력하여 복잡한 문제를 해결한 경험이 많습니다.\",\n",
    "             metadata={\"experience\": \"3년간 데이터 분석 경험\", \"skills\": \"Data Analysis, Problem Solving, Collaboration\", \"education\": \"컴퓨터 공학 학사\", \"year\": 1995}),\n",
    "    Document(page_content=\"성격: 창의적이고 혁신적인 아이디어를 제시하는 것을 좋아하는 후보자. 새로운 기술과 트렌드를 빠르게 학습하고 프로젝트에 적용하는 데 강점을 보입니다.\",\n",
    "             metadata={\"experience\": \"4년간 제품 개발 경험\", \"skills\": \"Creativity, Innovation, Rapid Learning\", \"education\": \"전자공학 석사\", \"year\": 1998}),\n",
    "    Document(page_content=\"성격: 친화력이 뛰어나며, 고객과의 소통을 중시하는 후보자. 고객 만족도를 높이기 위한 전략을 수립하고 실행한 경험이 있습니다.\",\n",
    "             metadata={\"experience\": \"5년간 고객 서비스 관리 경험\", \"skills\": \"Customer Relations, Communication, Strategy\", \"education\": \"경영학 학사\", \"year\": 2000}),\n",
    "    Document(page_content=\"성격: 꼼꼼하고 정확한 성격을 가진 후보자. 다양한 프로젝트에서 기술적 문제를 해결하고 효율성을 극대화한 경험이 있습니다.\",\n",
    "             metadata={\"experience\": \"6년간 엔지니어링 경험\", \"skills\": \"Attention to Detail, Efficiency, Technical Problem Solving\", \"education\": \"기계공학 석사\", \"year\": 2002}),\n",
    "    Document(page_content=\"성격: 유연하고 적응력이 뛰어난 후보자. 빠르게 변화하는 환경에서의 문제 해결 경험이 많으며, 새로운 상황에 맞는 최적의 솔루션을 제시합니다.\",\n",
    "             metadata={\"experience\": \"4년간 IT 프로젝트 경험\", \"skills\": \"Adaptability, Problem Solving, Innovation\", \"education\": \"정보기술학 학사\", \"year\": 2001}),\n",
    "    Document(page_content=\"성격: 도전적이고 목표 지향적인 성격을 가진 후보자. 어려운 과제를 맡아 성과를 이끌어내며, 강한 동기부여를 가지고 일하는 특징이 있습니다.\",\n",
    "             metadata={\"experience\": \"5년간 마케팅 전략 경험\", \"skills\": \"Challenge, Goal-Oriented, Marketing Strategy\", \"education\": \"마케팅 학사\", \"year\": 1997}),\n",
    "    Document(page_content=\"성격: 팀워크를 중시하고 타인의 의견을 존중하는 후보자. 협업을 통해 성과를 도출해낸 경험이 많으며, 팀 내에서 중요한 역할을 맡고 있습니다.\",\n",
    "             metadata={\"experience\": \"3년간 프로젝트 협업 경험\", \"skills\": \"Teamwork, Collaboration, Leadership\", \"education\": \"사회학 석사\", \"year\": 1994}),\n",
    "    Document(page_content=\"성격: 분석적이며, 데이터를 바탕으로 의사결정을 내리는 것을 선호하는 후보자. 문제의 본질을 파악하고, 체계적인 방법으로 해결책을 제시합니다.\",\n",
    "             metadata={\"experience\": \"7년간 데이터 분석 및 연구 경험\", \"skills\": \"Analytical Thinking, Data-Driven Decision Making, Research\", \"education\": \"통계학 석사\", \"year\": 1999}),\n",
    "    Document(page_content=\"성격: 끈기 있고, 목표를 달성하기 위해 노력하는 성격을 가진 후보자. 어떤 어려움도 이겨내며 주어진 목표를 달성해낸 경험이 있습니다.\",\n",
    "             metadata={\"experience\": \"6년간 프로젝트 매니지먼트 경험\", \"skills\": \"Persistence, Goal Achievement, Project Management\", \"education\": \"토목공학 학사\", \"year\": 2003}),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3488/2490879139.py:5: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=model_name,\n",
      "2024-12-05 17:30:01.363033: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733387401.382973    3488 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733387401.389321    3488 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-05 17:30:01.410199: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "model_name = \"jhgan/ko-sbert-nli\" # 임베딩 이용\n",
    "encode_kwargs = {\"normalize_embeddings\": True}\n",
    "embeddings = HuggingFaceEmbeddings(model_name=model_name,\n",
    "                                   encode_kwargs=encode_kwargs)\n",
    "\n",
    "vectorstore=Chroma.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"api_keys.json\") as f:\n",
    "    OPENAI_API_KEY = json.load(f)[\"openai\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# 메타데이터 필드 정보 리스트 정의\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name = \"experience\",\n",
    "        description = \"The professional experience of the candidate\",\n",
    "        type = \"string\"\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name = \"skills\",\n",
    "        description = \"The skills possessed by the candidate\",\n",
    "        type = \"string\"\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name = \"education\",\n",
    "        description = \"The educational background of the candidate\",\n",
    "        type = \"string\"\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name = \"year\",\n",
    "        description = \"The year of the candidate's birth\",\n",
    "        type = \"integer\"\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM 모델 초기화\n",
    "llm = ChatOpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "# SelfQueryRetriever 생성\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm=llm,\n",
    "    vectorstore=vectorstore,\n",
    "    metadata_field_info=metadata_field_info,\n",
    "    document_contents=\"Candidate profile description\",\n",
    "    doc_content_description=\"A description of the candidate, including personality and experience.\",\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "성격: 창의적이고 혁신적인 아이디어를 제시하는 것을 좋아하는 후보자. 새로운 기술과 트렌드를 빠르게 학습하고 프로젝트에 적용하는 데 강점을 보입니다.\n",
      "education:전자공학 석사\n",
      "experience:4년간 제품 개발 경험\n",
      "skills:Creativity, Innovation, Rapid Learning\n",
      "year:1998\n",
      "-------------------------------------------------------\n",
      "성격: 유연하고 적응력이 뛰어난 후보자. 빠르게 변화하는 환경에서의 문제 해결 경험이 많으며, 새로운 상황에 맞는 최적의 솔루션을 제시합니다.\n",
      "education:정보기술학 학사\n",
      "experience:4년간 IT 프로젝트 경험\n",
      "skills:Adaptability, Problem Solving, Innovation\n",
      "year:2001\n",
      "-------------------------------------------------------\n",
      "성격: 적극적이고 리더십이 뛰어나며 팀워크를 중요시하는 후보자. 여러 프로젝트에서 리더 역할을 맡았으며, 목표 달성을 위한 헌신적인 노력으로 성과를 이끌어낸 경험이 있습니다.\n",
      "education:경영학 석사\n",
      "experience:5년간 프로젝트 관리 경험\n",
      "skills:Leadership, Teamwork, Project Management\n",
      "year:1993\n",
      "-------------------------------------------------------\n",
      "성격: 꼼꼼하고 정확한 성격을 가진 후보자. 다양한 프로젝트에서 기술적 문제를 해결하고 효율성을 극대화한 경험이 있습니다.\n",
      "education:기계공학 석사\n",
      "experience:6년간 엔지니어링 경험\n",
      "skills:Attention to Detail, Efficiency, Technical Problem Solving\n",
      "year:2002\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "query = \"4년 이하의 경력을 가진 빠른 성장을 하는 후보\"\n",
    "results = retriever.get_relevant_documents(query)\n",
    "for doc in results:\n",
    "    print(doc.page_content)\n",
    "    for metak, metav in doc.metadata.items():\n",
    "        print(f\"{metak}:{metav}\")\n",
    "    print(\"-\"*55)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
